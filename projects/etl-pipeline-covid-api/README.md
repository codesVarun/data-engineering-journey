# ğŸ¦  ETL Pipeline for COVID-19 API using Airflow & Docker

This project is a **production-grade ETL pipeline** that ingests real-time COVID-19 statistics from a public API, transforms the data into structured formats, and loads it into a PostgreSQL database â€” all orchestrated by **Apache Airflow**, containerized with **Docker**, and managed with **Poetry** for dependency management.

---

## ğŸš€ Project Goals

- âœ… Automate COVID-19 data collection from a public API
- âœ… Clean and transform raw JSON into structured tables
- âœ… Persist data into a PostgreSQL warehouse
- âœ… Use Airflow to orchestrate daily ETL tasks
- âœ… Run everything in isolated containers using Docker Compose

---

## ğŸ“Š Use Case

This pipeline enables the automated collection of COVID-19 stats (cases, deaths, recoveries, etc.) at the **continent level**, including country mappings. The data can power dashboards, analytics, and trend reports for health orgs, journalists, or researchers.

---

## ğŸ“ Project Structure
<details> <summary>ğŸ“ Click to expand - Project Directory Tree</summary>
    ```
    etl-pipeline-covid-api/
    â”‚
    â”œâ”€â”€ dags/                  # Airflow DAGs for orchestration
    â”œâ”€â”€ scripts/               # ETL scripts: extract, transform, load
    â”‚   â”œâ”€â”€ extract.py
    â”‚   â”œâ”€â”€ transform.py
    â”‚   â”œâ”€â”€ load.py
    â”‚   â””â”€â”€ run_etl.py
    â”œâ”€â”€ .env                   # Environment variables (DB credentials, etc.)
    â”œâ”€â”€ Dockerfile             # Custom Airflow image with Poetry
    â”œâ”€â”€ docker-compose.yml     # Services: airflow, postgres, scheduler
    â”œâ”€â”€ pyproject.toml         # Poetry-based dependency management
    â””â”€â”€ README.md              # You are here
    ```
</details>
---

## ğŸ› ï¸ Tech Stack

| Tool        | Purpose                          |
|-------------|----------------------------------|
| Airflow     | Orchestration of ETL workflow    |
| Python      | Core ETL logic                   |
| Pandas      | Data transformation              |
| SQLAlchemy  | Database interaction             |
| PostgreSQL  | Data warehouse                   |
| Docker      | Containerization                 |
| Poetry      | Dependency management            |

---

## ğŸ”— Data Source

- **API**: [disease.sh - COVID-19 API](https://disease.sh/docs/#/)
- **Endpoint Used**: `https://disease.sh/v3/covid-19/continents`

---

## ğŸ§¬ ETL Flow

1. **Extract** (`extract.py`)
   - Pulls JSON data from the COVID-19 API.

2. **Transform** (`transform.py`)
   - Converts raw JSON into two normalized tables:
     - `covid_continent_stats`: core stats per continent
     - `covid_continent_countries`: mapping of continent â†’ countries

3. **Load** (`load.py`)
   - Inserts the transformed data into a PostgreSQL database.

4. **Orchestrate** (`run_etl.py` or Airflow DAG)
   - Runs the full ETL sequence in order.

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repo

```bash
git clone https://github.com/codesvarun/data-engineering-journey.git
cd data-engineering-journey/projects/etl-pipeline-covid-api