
---

### 📅 `daily-logs/06-08-2025.md`

```markdown
# 📅 Daily Log — 06-08-2025

## ✅ What I Did Today

- Fixed Airflow login issue by recreating user with `airflow users create ...`
- Successfully ran the `etl-pipeline-covid-api` DAG from Airflow UI and CLI
- Refactored ETL scripts into modular structure:
  - `extract.py`: API call
  - `transform.py`: JSON to DataFrame
  - `load.py`: Load into PostgreSQL
- Created and configured Docker services for:
  - Airflow Webserver
  - Scheduler
  - PostgreSQL
- Learned how Airflow executes DAGs and how logs are stored
- Wrote `README.md` for the COVID ETL project
- Structured repo into:
  - `projects/`
  - `notes/`
  - `daily-logs/`
  - `assets/diagrams/`
- Added directory tree and explanations to the project readme

## 🧠 Key Learnings

- Airflow's LocalExecutor can manage small DAGs locally
- How to run ETL both manually and via DAG
- Importance of `.env` config in `docker-compose.yml`
- Airflow DAGs must be idempotent and retry-safe

## 🔍 What’s Next

- Add Airflow DAG for another ETL use case (maybe weather, stock, or crypto data)
- Create notes for Kafka basics
- Setup a basic Superset or Streamlit dashboard on top of this data

---

🛤️ *Slowly but surely building the pipeline to mastery...*